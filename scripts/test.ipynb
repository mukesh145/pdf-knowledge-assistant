{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb86b113",
   "metadata": {},
   "source": [
    "### Query Processor testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37fca4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QueryProcessor initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import the QueryProcessor class\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd())))\n",
    "\n",
    "from src.agent.query_processing import QueryProcessor\n",
    "\n",
    "# Initialize the processor\n",
    "processor = QueryProcessor()\n",
    "print(\"QueryProcessor initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f5c5091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can you provide a more specific explanation from the book related to the Principle of Relativity (in the restricted sense), considering the scientific and philosophical implications as described in the context of relativity theory?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = \"Can YOu be More Specifc.\"\n",
    "processor.process(sample_text,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3d64eb",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b335074c",
   "metadata": {},
   "source": [
    "### Langgraph Orchestrator Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0145b748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    " \n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd())))\n",
    "\n",
    "from src.agent.orchestrator import run_ka_dag\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa88f465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide a simple test string\n",
    "input_query = \"what are  Diblock Copolymers ?\"\n",
    "\n",
    "# Call the run_ka_dag function\n",
    "result = run_ka_dag(input_query,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64a53e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query\n",
      "what are  Diblock Copolymers ?\n",
      "\n",
      "\n",
      "\n",
      "processed_query\n",
      "what are diblock copolymers ?\n",
      "\n",
      "\n",
      "\n",
      "is_rag_required\n",
      "True\n",
      "\n",
      "\n",
      "\n",
      "is_prev_memory_required\n",
      "False\n",
      "\n",
      "\n",
      "\n",
      "user_id\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "context\n",
      "Synthesis and Characterization of Postsulfonated Poly(arylene ether sulfone) Diblock Copolymers for Proton Exchange Membranes Fuel Cell Laboratory, Nissan Research Center, Nissan Motor Co., Ltd., 1 Natsushima-cho, Yokosuka-shi, Kanagawa 237-8523, Japan Received 10 November 2007; accepted 30 October 2008 DOI: 10.1002/pola.23181 Published online in Wiley InterScience (www.interscience.wiley.com). ABSTRACT: Sulfonated poly(arylene ether sulfone) diblock copolymers were studied through the postsulfonation process. Two kinds of hydrophobic oligomers with a mol- ecular weight of 20 kDa were prepared in advance as block sequences and then coupled together to obtain diblock copolymers. One oligomer was synthesized from bis(4-hydroxyphenyl) sulfone (BHPS) and 4,40-diﬂuorodiphenyl sulfone (DFDPS), which was thought to be incapable of postsulfonation. The other oligomer was syn- thesized from hydroquinone (HQ) and 4,40-dichlorodiphenyl sulfone (DCDPS), which successfully proceeded to a hydrophilic sequence as a result of sulfonation onto the HQ moiety after the coupling reaction. Consequently, a diblock copolymer with high molecular weight was obtained; although its intrinsic viscosity was too low to form a tough membrane because of its high rigidity and high crystallinity. Therefore, the use of decaﬂuorobiphenyl (10F) as a termination reagent was investigated with the aim of achieving higher coupling reactivity and a kinky property. As a result, a sulfo- nated diblock copolymer was successfully obtained with sufﬁcient molecular weight and intrinsic viscosity to form the membrane, as well as with adequate thermal pro- perties. It was observed that proton conductivity, water uptake, and the water diffu- sion coefﬁcient increased with higher ion exchange capacity. VVC 2008 Wiley Periodicals, Inc. J Polym Sci Part A: Polym Chem 47: 700–712, 2009 For the last several decades, there has been increasing interest in polymer electrolyte mem- brane (PEM) fuel cells for application as station- ary, transportation, and portable power sources.1 Extensive research efforts have produced a wide variety of PEMs such as perﬂuorinated\n",
      "\n",
      "proton paths under low RH, despite having equal or higher PC under a fully hydrated condition. In recent years, many researchers have been searching for ways to com- pensate for this low PC such as by providing microphase separations. For direct-methanol fuel cell (DMFC) applications, a number of block copolymers based on poly(styrene-co-olefin) have been developed, resulting in better selectivities, yet they still have some inherently similar prob- lems to those of PSA membranes, because of their lower thermal stability than engineering plas- tics.° Recently, McGrath et al.7° have proposed that multiblock copolymers based on PES consist- ing of hydrophilic and hydrophobic sequences could improve PC under low RH because of the formation of continuous effective proton paths. However, there is a problem in synthesizing such multiblock copolymers via a polycondensation reaction because of the poor coupling reactivity between the two oligomers, which results in a lower molecular weight than that needed to form tough membranes. Considering the nucleophilic- ity of the terminated structures, poly(imide) type block copolymers can be easily polymerized; although the issue of hydrolysis has not been thoroughly resolved so far.!°-!% Therefore, the aim of this study was to enhance the reactivity of the coupling reaction by using Therefore, the aim of this study was to enhance the reactivity of the coupling reaction by using two hydrophobic oligomers that can be expected to provide more mutual miscibility than hydro- philic–hydrophobic oligomers, as well as highly reactive ﬂuorine-extermination moieties instead of chlorine.7,14–16 With regard to the raw material cost, hydroquinone (HQ), as a commercially avail- able dihydroxyl monomer, is more readily usable, compared with even well-known monomers such as biphenol, bisphenol A, and bisphenol AF. Some researchers have been investigating the use of a sulfonated HQ monomer17,18 or a postsulfona- tion process after polymerization,19 but these approaches have\n",
      "\n",
      "AFM images [height mode (left), phase mode (right)] of sulfonated diblock copolymer. and chemical properties. The AFM images in Fig- ure 15 also conﬁrmed the phase separation of the hydrophobic region (light color) and hydrophilic region (dark color), indicating that both partially continuous and isolated phase separations exist. In summary, both PC and the water self-diffusion coefﬁcient were lower than we expected, because of the strength of proton association that is de- pendent on the chemical structure, as well as the insufﬁcient phase separation due to randomly postsulfonated structure. The synthesis of postsulfonated, hydroquinone- based diblock copolymers was investigated by means of highly reactive ﬂuorine-terminated reagents. The use of HQ led to some crystallinity and sol- ubility problems in the oligomer consisting of HQ and 4,40-dichlorodiphenyl sulfone. 4,40-Diﬂuorodi- phenyl sulfone was used as the termination rea- gent for the ether sulfone-based oligomer. It was found that intrinsic viscosity decreased with a higher molecular weight, even for the random copolymers. In contrast, decaﬂuorobiphenyl worked very effectively as the termination reagent and resulted in a successful synthesis of a diblock co- polymer with sufﬁcient molecular weight and intrinsic viscosity to form a tough membrane. Postsulfonation was successfully induced in the diblock copolymer without any degradation. It was observed that the degree of sulfonation was controllable by changing the reaction time. In addition, the postsulfonated diblock copolymer was conﬁrmed to have sufﬁcient thermal stability. The characterization results confirmed thermal stability at a temperature of at least 200 °C, T, of 156 °C and T,, of 247 °C. Additionally, tensile Journal of Polymer Science: Part A: Polymer Chemistry DOI 10.1002/pola strength at fracture was conﬁrmed to be 38.98 MPa even in the hydrated state. It was observed that proton conductivity, water uptake, and the water self-diffusion coefﬁcient increased with increasing IEC. The authors thank\n",
      "\n",
      "property of 10F enabled the formation of kinky polymer chains that resulted in highly entangled polymeric physical structures, which would account for the high values. This successful diblock copolymer (B5, s-B5) is discussed in the fol- lowing section. The glass transition point (T,) of the 10F-based diblock copolymer was evaluated using DSC mea- surement by heating samples from 50 to 300 °C at a rate of 5 °C/min, as shown in Figure 11. Looking at the diblock copolymer before sulfonation, a peak due to T, was detected at 156 °C, corre- sponding to the PES block sequences, since it also appeared at almost the same temperature after sulfonation. A large peak also appeared at 247 °C, which is likely the melting point (7,,) mainly due Journal of Polymer Science: Part A: Polymer Chemistry DOI 10.1002/pola Before sulfonation 3 a ps T, 1s7¢ 4 After sulfonation 50 100 150 200 250 300 Temperature (degrees C) Figure 11. DSC curves of diblock copolymers with 10F as a connection before (B5) and after sulfonation (s-B5), at a heating rate of 5 °C/min. to PEES. After sulfonation, the peak intensity decreased. This is because the sulfonate group associates and increases intermolecular interac- tion, hence reducing molecular mobility. The thermal decomposition point (Ty) was also studied using TGA measurement in a tempera- ture range from 50 to 400 °C at a heating rate of 5 °C/min. The results are shown in Figure 12. Although the diblock copolymer before sulfonation was stable until 300 °C without any weight loss, the sulfonated sample showed slight degradation at 200 °C, resulting in a 5% weight loss at 295 °C and a 10% weight loss at 340 °C. The Tq for this sulfonated diblock copolymer was lower than that reported in the reference.?” The reason can be explained by\n",
      "\n",
      "31.161 mmol), DCDPS (5.0335 g, 30.6610 mmol), and K2CO3 (5.03 g, 36.1 mmol) were put together in NMP (60 mL, 20 v/w%) with toluene (30 mL). The solution was first heated to 60 °C for 4 h and then to 190 °C for 2 days. The filtered solution was kept in nitrogen gas without any isolation treat- ment until the coupling reaction. This oligomer is referred to as PEES in this article. BHPS (5.3192 g, 21.255 mmol), DFDPS (5.5311 g, 21.755 mmol), and KaCO3 (3.38 g, 24.5 mmol) were added to NMP (60 mL) with toluene (30 mL). The solution was first heated to 160 °C for 4 h and Figure 4 shows the coupling reaction of the diblock copolymer consisting of the PEES and PES-F oligomers. The stoichiometric ratio (1:1) of PEES to PES-F was calculated from the ideal molar numbers in each solution under the assumption that each could have a molecular weight of 20 kDa. Both prepared solutions were put in a flask in addition to a small amount of K,CO3 (equivalent to 1.15 times the amount of PEES) and toluene (half the volume of NMP). The solution mixture was heated to 130 °C for 6 h, and then the completion temperature was investi- gated by setting the temperature at various levels of 100, 130, 160, and 190 °C. After 4 days, the so- lution was isolated in methanol and dried in a vacuum oven at 80°C. ; co a a - wo—{ on 2.190C, 2days ° , Y + off S—o—{ an J )—-oK OLO OO F i F + HO { OH 2 190C, 24a ° ° / iN i i HC) i {_ \\ HC) i ( )-F Figure 2. Synthesis of OH-terminated poly(ether ether sulfone) oligomer (PEES). Figure 3. Synthesis of F-terminated poly(ether\n",
      "\n",
      "\n",
      "\n",
      "memory\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "llm_response\n",
      "Diblock copolymers are a type of block copolymer composed of two distinct polymer blocks linked together. In the context provided, diblock copolymers specifically refer to those synthesized for use in proton exchange membranes, involving hydrophobic and hydrophilic sequences. The article discusses the synthesis of sulfonated poly(arylene ether sulfone) diblock copolymers, which are chemically modified to improve their properties such as molecular weight, intrinsic viscosity, and thermal stability, making them suitable for applications like polymer electrolyte membrane fuel cells. These copolymers are created by coupling two different oligomer sequences, resulting in a material capable of forming a membrane with enhanced proton conductivity and thermal properties suitable for fuel cell applications.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in result.keys():\n",
    "    print(k)\n",
    "    print(result[k])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdc27ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: How does this compare to traditional methods?\n",
      "Assistant: Compared to traditional methods, the approach shows 15-20% improvement in accuracy, but requires 3x more computational resources. The trade-off is generally favorable for large-scale applications.\n",
      "\n",
      "User: What are the recommended next steps?\n",
      "Assistant: The recommended next steps include: expanding the dataset, experimenting with different architectures, implementing ensemble methods, and conducting real-world validation studies.\n",
      "\n",
      "User: Can you summarize the key findings?\n",
      "Assistant: The key findings include: 1) Neural networks show superior performance on complex datasets, 2) Transfer learning significantly reduces training time, 3) Data preprocessing is crucial for model accuracy.\n"
     ]
    }
   ],
   "source": [
    "print(result['memory'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07be200e",
   "metadata": {},
   "source": [
    "### Intent Classifier Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9d094e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing IntentClassifier...\n",
      "IntentClassifier initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import the IntentClassifier class\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src', 'agent'))\n",
    "\n",
    "from src.agent.intent_classifier import IntentClassifier\n",
    "\n",
    "# Initialize the classifier\n",
    "print(\"Initializing IntentClassifier...\")\n",
    "classifier = IntentClassifier()\n",
    "print(\"IntentClassifier initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "062a7f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing IntentClassifier with various queries:\n",
      "======================================================================\n",
      "\n",
      "Query: 'Tell me about Toyota's Internal AI System'\n",
      "  RAG Required: True\n",
      "  Previous Memory Required: False\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Query: 'Tell me about the previous conversation'\n",
      "  RAG Required: False\n",
      "  Previous Memory Required: True\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Query: 'What did we discuss earlier?'\n",
      "  RAG Required: False\n",
      "  Previous Memory Required: True\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Query: 'Hello, how are you?'\n",
      "  RAG Required: False\n",
      "  Previous Memory Required: False\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Query: 'What was the last thing you told me?'\n",
      "  RAG Required: False\n",
      "  Previous Memory Required: True\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Query: 'How does neural network work?'\n",
      "  RAG Required: False\n",
      "  Previous Memory Required: False\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Query: 'Can you remind me what we talked about?'\n",
      "  RAG Required: False\n",
      "  Previous Memory Required: True\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test the IntentClassifier with various queries\n",
    "test_queries = [\n",
    "    \"Tell me about Toyota's Internal AI System\",\n",
    "    \"Tell me about the previous conversation\",\n",
    "    \"What did we discuss earlier?\",\n",
    "    \"Hello, how are you?\",\n",
    "    \"What was the last thing you told me?\",\n",
    "    \"How does neural network work?\",\n",
    "    \"Can you remind me what we talked about?\",\n",
    "]\n",
    "\n",
    "print(\"Testing IntentClassifier with various queries:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for query in test_queries:\n",
    "    result = classifier.classify(query)\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    print(f\"  RAG Required: {result['is_rag_required']}\")\n",
    "    print(f\"  Previous Memory Required: {result['is_prev_memory_required']}\")\n",
    "    print(\"-\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e80817",
   "metadata": {},
   "source": [
    "### Context Retriever Testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151dcbc5",
   "metadata": {},
   "source": [
    "### Memory Retriever Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec69597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing MemoryRetriever...\n",
      "MemoryRetriever initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import the MemoryRetriever class\n",
    "import sys\n",
    "import os\n",
    "# print(os.path.join(os.path.dirname(os.getcwd()),'src'))\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd())))\n",
    "\n",
    "from src.agent.memory_retriever import MemoryRetriever\n",
    "\n",
    "# Initialize the retriever\n",
    "print(\"Initializing MemoryRetriever...\")\n",
    "memory_retriever = MemoryRetriever()\n",
    "print(\"MemoryRetriever initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "729db827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MemoryRetriever with user_id = 1:\n",
      "======================================================================\n",
      "\n",
      "User ID: 1\n",
      "----------------------------------------------------------------------\n",
      "Past Conversations Retrieved:\n",
      "----------------------------------------------------------------------\n",
      "User: How does this compare to traditional methods?\n",
      "Assistant: Compared to traditional methods, the approach shows 15-20% improvement in accuracy, but requires 3x more computational resources. The trade-off is generally favorable for large-scale applications.\n",
      "\n",
      "User: What are the recommended next steps?\n",
      "Assistant: The recommended next steps include: expanding the dataset, experimenting with different architectures, implementing ensemble methods, and conducting real-world validation studies.\n",
      "\n",
      "User: Can you summarize the key findings?\n",
      "Assistant: The key findings include: 1) Neural networks show superior performance on complex datasets, 2) Transfer learning significantly reduces training time, 3) Data preprocessing is crucial for model accuracy.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "✓ Successfully retrieved past conversations for user_id 1\n",
      "======================================================================\n",
      "\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "# Test the MemoryRetriever with user_id = 1\n",
    "print(\"Testing MemoryRetriever with user_id = 1:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # Fetch past conversations for user_id = 1\n",
    "    user_id = 1\n",
    "    conversations = memory_retriever.get_past_conversations(user_id)\n",
    "    \n",
    "    print(f\"\\nUser ID: {user_id}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    if conversations:\n",
    "        print(\"Past Conversations Retrieved:\")\n",
    "        print(\"-\" * 70)\n",
    "        print(conversations)\n",
    "        print(\"-\" * 70)\n",
    "        print(f\"\\n✓ Successfully retrieved past conversations for user_id {user_id}\")\n",
    "    else:\n",
    "        print(\"No past conversations found for this user_id.\")\n",
    "        print(\"-\" * 70)\n",
    "        print(f\"\\n✓ Query executed successfully, but no conversations found for user_id {user_id}\")\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n✗ Error occurred: {str(e)}\")\n",
    "    print(\"=\" * 70)\n",
    "finally:\n",
    "    # Close the database connection\n",
    "    memory_retriever.close_connection()\n",
    "    print(\"\\nDatabase connection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65015555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ContextRetriever...\n",
      "ContextRetriever initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import the ContextRetriever class\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src', 'agent'))\n",
    "\n",
    "from src.agent.context_retriever import ContextRetriever\n",
    "\n",
    "# Initialize the retriever\n",
    "print(\"Initializing ContextRetriever...\")\n",
    "retriever = ContextRetriever()\n",
    "print(\"ContextRetriever initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11ef36d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing convert_to_embeddings function:\n",
      "======================================================================\n",
      "Input sentence: 'This is a simple test sentence.'\n",
      "----------------------------------------------------------------------\n",
      "Embedding type: <class 'numpy.ndarray'>\n",
      "Embedding shape: (1024,)\n",
      "Embedding dimensions: 1024\n",
      "Expected dimensions: 1024\n",
      "----------------------------------------------------------------------\n",
      "✓ Test Result: PASSED - Returns 1024-dimensional vector!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test the convert_to_embeddings function\n",
    "test_sentence = \"This is a simple test sentence.\"\n",
    "\n",
    "print(\"Testing convert_to_embeddings function:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Input sentence: '{test_sentence}'\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Convert to embeddings\n",
    "embeddings = retriever.convert_to_embeddings(test_sentence)\n",
    "\n",
    "# Check the result\n",
    "print(f\"Embedding type: {type(embeddings)}\")\n",
    "print(f\"Embedding shape: {embeddings.shape}\")\n",
    "print(f\"Embedding dimensions: {embeddings.shape[0] if len(embeddings.shape) == 1 else embeddings.shape}\")\n",
    "print(f\"Expected dimensions: 1024\")\n",
    "\n",
    "# Verify it's a 1024-dimensional vector\n",
    "is_1024_dim = len(embeddings.shape) == 1 and embeddings.shape[0] == 1024\n",
    "status = \"✓\" if is_1024_dim else \"✗\"\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(f\"{status} Test Result: {'PASSED - Returns 1024-dimensional vector!' if is_1024_dim else 'FAILED - Does not return 1024-dimensional vector!'}\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe581fa",
   "metadata": {},
   "source": [
    "### LLM Orchestrator Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9ebd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing LLMOrchestrator...\n",
      "LLMOrchestrator initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import the LLMOrchestrator class\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd())))\n",
    "\n",
    "from src.agent.llm_orchestrator import LLMOrchestrator\n",
    "\n",
    "# Initialize the orchestrator\n",
    "print(\"Initializing LLMOrchestrator...\")\n",
    "orchestrator = LLMOrchestrator()\n",
    "print(\"LLMOrchestrator initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a41f4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing LLMOrchestrator with various scenarios:\n",
      "======================================================================\n",
      "\n",
      "1. Test with context and past conversation:\n",
      "----------------------------------------------------------------------\n",
      "Query: What is the coupling reaction mentioned in the research paper?\n",
      "\n",
      "Answer:\n",
      "The coupling reaction mentioned in the research paper refers to the process of connecting two oligomers to form diblock copolymers. This is achieved using a termination reagent like decafluorobiphenyl (10F). The reaction requires high temperatures of at least 160°C to proceed successfully.\n",
      "\n",
      "✓ Test 1 passed!\n",
      "\n",
      "\n",
      "2. Test with only context (past_conversation=None):\n",
      "----------------------------------------------------------------------\n",
      "Query: What temperature is required for the coupling reaction?\n",
      "\n",
      "Answer:\n",
      "The coupling reaction requires a temperature of 160°C or higher to be successful.\n",
      "\n",
      "✓ Test 2 passed!\n",
      "\n",
      "\n",
      "3. Test with only past conversation (context=None):\n",
      "----------------------------------------------------------------------\n",
      "Query: Can you remind me what we discussed about copolymers?\n",
      "\n",
      "Answer:\n",
      "In our previous conversation, we discussed diblock copolymers. These are polymers consisting of two distinct block sequences that are chemically linked together. They are commonly used in applications such as fuel cells. If you have more questions about copolymers or need more details, feel free to ask!\n",
      "\n",
      "✓ Test 3 passed!\n",
      "\n",
      "\n",
      "4. Test with neither context nor past conversation (both None):\n",
      "----------------------------------------------------------------------\n",
      "Query: What is machine learning?\n",
      "\n",
      "Answer:\n",
      "Machine learning is a branch of artificial intelligence (AI) that focuses on the development of algorithms and statistical models that enable computers to perform tasks without explicit instructions. Instead, these systems learn from and make decisions based on data. Machine learning algorithms build a model based on sample data, known as training data, to make predictions or decisions without being explicitly programmed to perform the task. It is widely used in various fields such as speech recognition, image processing, and predictive analytics.\n",
      "\n",
      "✓ Test 4 passed!\n",
      "\n",
      "\n",
      "5. Test with empty strings:\n",
      "----------------------------------------------------------------------\n",
      "Query: Explain quantum computing.\n",
      "\n",
      "Answer:\n",
      "Quantum computing is a type of computation that takes advantage of the principles of quantum mechanics, which is a fundamental theory in physics describing the physical properties of nature at the scale of atoms and subatomic particles. Quantum computers use quantum bits, or qubits, instead of classical bits to process information.\n",
      "\n",
      "Unlike classical bits, which can be either 0 or 1, qubits can exist in multiple states at once thanks to a property called superposition. This allows quantum computers to process a massive amount of possibilities simultaneously. Another key principle, entanglement, allows qubits that are entangled to influence one another instantaneously, regardless of the distance separating them, providing a powerful means to perform complex computations more efficiently than classical computers.\n",
      "\n",
      "Quantum computing holds promise for solving certain problems much faster than classical computers can. These include factoring large numbers, searching large databases, and simulating quantum physical processes. However, quantum computing is still largely in the experimental and developmental stages, with significant technical challenges remaining to be solved before it becomes practical for widespread use.\n",
      "\n",
      "✓ Test 5 passed!\n",
      "\n",
      "======================================================================\n",
      "All LLMOrchestrator tests completed!\n"
     ]
    }
   ],
   "source": [
    "# Test the LLMOrchestrator with various scenarios\n",
    "print(\"Testing LLMOrchestrator with various scenarios:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Test case 1: With context and past conversation\n",
    "print(\"\\n1. Test with context and past conversation:\")\n",
    "print(\"-\" * 70)\n",
    "test_query_1 = \"What is the coupling reaction mentioned in the research paper?\"\n",
    "test_context_1 = \"The coupling reaction of diblock copolymers involves connecting two oligomers using a termination reagent like decafluorobiphenyl (10F). The reaction requires temperatures of 160°C or higher to be successful.\"\n",
    "test_past_conversation_1 = \"User: What are diblock copolymers?\\nAssistant: Diblock copolymers are polymers consisting of two distinct block sequences that are chemically linked together.\"\n",
    "\n",
    "try:\n",
    "    answer_1 = orchestrator.generate_response(\n",
    "        query=test_query_1,\n",
    "        context=test_context_1,\n",
    "        past_conversation=test_past_conversation_1\n",
    "    )\n",
    "    print(f\"Query: {test_query_1}\")\n",
    "    print(f\"\\nAnswer:\\n{answer_1}\")\n",
    "    print(\"\\n✓ Test 1 passed!\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Test 1 failed: {str(e)}\")\n",
    "\n",
    "# Test case 2: With only context (no past conversation)\n",
    "print(\"\\n\\n2. Test with only context (past_conversation=None):\")\n",
    "print(\"-\" * 70)\n",
    "test_query_2 = \"What temperature is required for the coupling reaction?\"\n",
    "test_context_2 = \"The coupling reaction requires a temperature of 160°C or higher to be successful. At lower temperatures like 100°C or 130°C, the reaction was not successful.\"\n",
    "\n",
    "try:\n",
    "    answer_2 = orchestrator.generate_response(\n",
    "        query=test_query_2,\n",
    "        context=test_context_2,\n",
    "        past_conversation=None\n",
    "    )\n",
    "    print(f\"Query: {test_query_2}\")\n",
    "    print(f\"\\nAnswer:\\n{answer_2}\")\n",
    "    print(\"\\n✓ Test 2 passed!\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Test 2 failed: {str(e)}\")\n",
    "\n",
    "# Test case 3: With only past conversation (no context)\n",
    "print(\"\\n\\n3. Test with only past conversation (context=None):\")\n",
    "print(\"-\" * 70)\n",
    "test_query_3 = \"Can you remind me what we discussed about copolymers?\"\n",
    "test_past_conversation_3 = \"User: What are diblock copolymers?\\nAssistant: Diblock copolymers are polymers consisting of two distinct block sequences that are chemically linked together. They are used in various applications including fuel cells.\"\n",
    "\n",
    "try:\n",
    "    answer_3 = orchestrator.generate_response(\n",
    "        query=test_query_3,\n",
    "        context=None,\n",
    "        past_conversation=test_past_conversation_3\n",
    "    )\n",
    "    print(f\"Query: {test_query_3}\")\n",
    "    print(f\"\\nAnswer:\\n{answer_3}\")\n",
    "    print(\"\\n✓ Test 3 passed!\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Test 3 failed: {str(e)}\")\n",
    "\n",
    "# Test case 4: With neither context nor past conversation (both None)\n",
    "print(\"\\n\\n4. Test with neither context nor past conversation (both None):\")\n",
    "print(\"-\" * 70)\n",
    "test_query_4 = \"What is machine learning?\"\n",
    "\n",
    "try:\n",
    "    answer_4 = orchestrator.generate_response(\n",
    "        query=test_query_4,\n",
    "        context=None,\n",
    "        past_conversation=None\n",
    "    )\n",
    "    print(f\"Query: {test_query_4}\")\n",
    "    print(f\"\\nAnswer:\\n{answer_4}\")\n",
    "    print(\"\\n✓ Test 4 passed!\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Test 4 failed: {str(e)}\")\n",
    "\n",
    "# Test case 5: With empty strings\n",
    "print(\"\\n\\n5. Test with empty strings:\")\n",
    "print(\"-\" * 70)\n",
    "test_query_5 = \"Explain quantum computing.\"\n",
    "\n",
    "try:\n",
    "    answer_5 = orchestrator.generate_response(\n",
    "        query=test_query_5,\n",
    "        context=\"\",\n",
    "        past_conversation=\"\"\n",
    "    )\n",
    "    print(f\"Query: {test_query_5}\")\n",
    "    print(f\"\\nAnswer:\\n{answer_5}\")\n",
    "    print(\"\\n✓ Test 5 passed!\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Test 5 failed: {str(e)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"All LLMOrchestrator tests completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223843bf",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7440366",
   "metadata": {},
   "source": [
    "### Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aa7da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Logger...\n",
      "Logger initialized successfully!\n",
      "✓ Database connection established in __init__\n"
     ]
    }
   ],
   "source": [
    "# Import the Logger class\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd())))\n",
    "\n",
    "from src.agent.logger import Logger\n",
    "\n",
    "# Initialize the logger\n",
    "print(\"Initializing Logger...\")\n",
    "logger = Logger()\n",
    "print(\"Logger initialized successfully!\")\n",
    "print(\"✓ Database connection established in __init__\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "557b3902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing save_conversation method:\n",
      "======================================================================\n",
      "✓ Successfully saved conversation to 'conversation_history' table\n",
      "  User ID: 1\n",
      "  Query: What is machine learning?\n",
      "  Response: Machine learning is a branch of artificial intelli...\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test save_conversation method\n",
    "print(\"Testing save_conversation method:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "test_user_id = 1\n",
    "test_query = \"What is machine learning?\"\n",
    "test_llm_response = \"Machine learning is a branch of artificial intelligence that enables computers to learn from data without being explicitly programmed.\"\n",
    "\n",
    "try:\n",
    "    logger.save_conversation(\n",
    "        user_id=test_user_id,\n",
    "        query=test_query,\n",
    "        llm_response=test_llm_response\n",
    "    )\n",
    "    print(f\"✓ Successfully saved conversation to 'conversation_history' table\")\n",
    "    print(f\"  User ID: {test_user_id}\")\n",
    "    print(f\"  Query: {test_query}\")\n",
    "    print(f\"  Response: {test_llm_response[:50]}...\")\n",
    "    print(\"=\" * 70)\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error saving conversation: {str(e)}\")\n",
    "    print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "226528e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing save_logs method:\n",
      "======================================================================\n",
      "✓ Successfully saved state to 'logs' table\n",
      "  User ID: 1\n",
      "  Query: What is the coupling reaction?\n",
      "  Processed Query: what is the coupling reaction\n",
      "  Context: The coupling reaction involves connecting two olig...\n",
      "  Past Memory: []\n",
      "  LLM Response: The coupling reaction is a process that connects t...\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test save_logs method\n",
    "print(\"Testing save_logs method:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create a sample state dictionary matching the logs table schema\n",
    "test_state = {\n",
    "    \"u_id\": 1,\n",
    "    \"query\": \"What is the coupling reaction?\",\n",
    "    \"processed_query\": \"what is the coupling reaction\",\n",
    "    \"context\": \"The coupling reaction involves connecting two oligomers using decafluorobiphenyl (10F) at 160°C.\",\n",
    "    \"past_memory\": \"[]\",\n",
    "    \"llm_response\": \"The coupling reaction is a process that connects two oligomers to form diblock copolymers using a termination reagent.\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    logger.save_logs(state=test_state)\n",
    "    print(f\"✓ Successfully saved state to 'logs' table\")\n",
    "    print(f\"  User ID: {test_state['u_id']}\")\n",
    "    print(f\"  Query: {test_state['query']}\")\n",
    "    print(f\"  Processed Query: {test_state['processed_query']}\")\n",
    "    print(f\"  Context: {test_state['context'][:50]}...\")\n",
    "    print(f\"  Past Memory: {test_state['past_memory']}\")\n",
    "    print(f\"  LLM Response: {test_state['llm_response'][:50]}...\")\n",
    "    print(\"=\" * 70)\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error saving logs: {str(e)}\")\n",
    "    print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6c02cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing save_logs with orchestrator state format:\n",
      "======================================================================\n",
      "✓ Successfully saved orchestrator state to 'logs' table\n",
      "  Note: Mapped 'user_id' -> 'u_id' and 'memory' -> 'past_memory'\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test with a state from the orchestrator (mapping user_id to u_id)\n",
    "print(\"Testing save_logs with orchestrator state format:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Simulate a state from run_ka_dag (which uses 'user_id' instead of 'u_id')\n",
    "orchestrator_state = {\n",
    "    \"query\": \"Hi\",\n",
    "    \"processed_query\": \"hi\",\n",
    "    \"is_rag_required\": False,\n",
    "    \"is_prev_memory_required\": False,\n",
    "    \"user_id\": 1,  # Note: orchestrator uses 'user_id'\n",
    "    \"context\": \"\",\n",
    "    \"memory\": \"\",\n",
    "    \"llm_response\": \"Hello! How can I assist you today?\"\n",
    "}\n",
    "\n",
    "# Map user_id to u_id and memory to past_memory for the logs table\n",
    "logs_state = {\n",
    "    \"u_id\": orchestrator_state.get(\"user_id\"),\n",
    "    \"query\": orchestrator_state.get(\"query\"),\n",
    "    \"processed_query\": orchestrator_state.get(\"processed_query\"),\n",
    "    \"context\": orchestrator_state.get(\"context\"),\n",
    "    \"past_memory\": orchestrator_state.get(\"memory\", \"[]\"),\n",
    "    \"llm_response\": orchestrator_state.get(\"llm_response\")\n",
    "}\n",
    "\n",
    "try:\n",
    "    logger.save_logs(state=logs_state)\n",
    "    print(f\"✓ Successfully saved orchestrator state to 'logs' table\")\n",
    "    print(f\"  Note: Mapped 'user_id' -> 'u_id' and 'memory' -> 'past_memory'\")\n",
    "    print(\"=\" * 70)\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error saving logs: {str(e)}\")\n",
    "    print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88f377cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying saved data and cleaning up:\n",
      "======================================================================\n",
      "✓ Found 1 matching record(s) in conversation_history\n",
      "✓ Found 1 matching record(s) in logs\n",
      "======================================================================\n",
      "✓ Database connection closed successfully\n",
      "======================================================================\n",
      "All Logger tests completed!\n"
     ]
    }
   ],
   "source": [
    "# Verify data was saved and close connection\n",
    "print(\"Verifying saved data and cleaning up:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # Get database connection to verify\n",
    "    conn = logger._get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Check conversation_history\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT COUNT(*) FROM conversation_history \n",
    "        WHERE user_id = %s AND user_query = %s\n",
    "    \"\"\", (test_user_id, test_query))\n",
    "    conv_count = cursor.fetchone()[0]\n",
    "    print(f\"✓ Found {conv_count} matching record(s) in conversation_history\")\n",
    "    \n",
    "    # Check logs (if table exists)\n",
    "    try:\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT COUNT(*) FROM logs \n",
    "            WHERE u_id = %s AND query = %s\n",
    "        \"\"\", (test_state['u_id'], test_state['query']))\n",
    "        logs_count = cursor.fetchone()[0]\n",
    "        print(f\"✓ Found {logs_count} matching record(s) in logs\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Could not verify logs table: {str(e)}\")\n",
    "        print(\"  (Table may need to be created manually)\")\n",
    "    \n",
    "    cursor.close()\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error verifying data: {str(e)}\")\n",
    "    print(\"=\" * 70)\n",
    "finally:\n",
    "    # Close the database connection\n",
    "    logger.close_connection()\n",
    "    print(\"✓ Database connection closed successfully\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"All Logger tests completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35e3802",
   "metadata": {},
   "source": [
    "### Knowledge Extractor Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "149a8f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/miniconda3/envs/mlops/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing KnowledgeExtractor...\n",
      "Index test already exists\n",
      "Connected to index: test\n",
      "KnowledgeExtractor initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import the KnowledgeExtractor class\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd())))\n",
    "\n",
    "from src.knowledge.create_kb import KnowledgeExtractor\n",
    "\n",
    "# Initialize the KnowledgeExtractor\n",
    "# It will use environment variables for Pinecone configuration if not provided\n",
    "print(\"Initializing KnowledgeExtractor...\")\n",
    "try:\n",
    "    knowledge_extractor = KnowledgeExtractor()\n",
    "    print(\"KnowledgeExtractor initialized successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing KnowledgeExtractor: {str(e)}\")\n",
    "    print(\"Make sure PINECONE_API_KEY environment variable is set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69eb0331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing KnowledgeExtractor with book_1.pdf:\n",
      "======================================================================\n",
      "Processing PDF: book_1\n",
      "PDF path: /Users/user/Desktop/pdf-knowledge-assistant/test_data/book_1.pdf\n",
      "--------------------------------------------------\n",
      "Step 1: Extracting paragraphs from PDF...\n",
      "Warning: No languages specified, defaulting to English.\n",
      "Extracted 447 paragraphs\n",
      "\n",
      "Step 2: Chunking paragraphs into 300-word segments with 50-word overlap...\n",
      "Created 123 chunks\n",
      "\n",
      "Step 3: Processing chunks...\n",
      "Processed 123 chunks\n",
      "\n",
      "Step 4: Converting chunks to embeddings...\n",
      "Processing batch 1/2 (100 chunks)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading batch 1 to Pinecone...\n",
      "Uploaded 100 vectors (Total: 100)\n",
      "Processing batch 2/2 (23 chunks)...\n",
      "Uploading batch 2 to Pinecone...\n",
      "Uploaded 23 vectors (Total: 123)\n",
      "\n",
      "==================================================\n",
      "Successfully uploaded 123 vectors to Pinecone!\n",
      "PDF: book_1\n",
      "Chunk size: 300 words, Overlap: 50 words\n",
      "==================================================\n",
      "\n",
      "======================================================================\n",
      "Test Results:\n",
      "======================================================================\n",
      "✓ PDF Name: book_1\n",
      "✓ Paragraphs Extracted: 447\n",
      "✓ Chunks Created: 123\n",
      "✓ Vectors Uploaded to VectorDB: 123\n",
      "======================================================================\n",
      "✓ Knowledge extraction and storage completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Test KnowledgeExtractor with book_1.pdf\n",
    "print(\"Testing KnowledgeExtractor with book_1.pdf:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Path to the PDF file (relative to project root)\n",
    "pdf_path = \"test_data/book_1.pdf\"\n",
    "\n",
    "# Configuration for chunking\n",
    "chunk_size = 300  # Number of words per chunk\n",
    "overlap = 50      # Number of overlapping words between chunks\n",
    "batch_size = 100  # Number of chunks to process in each batch\n",
    "\n",
    "try:\n",
    "    # Extract, chunk, convert to embeddings, and store in vectordb\n",
    "    result = knowledge_extractor.extract(\n",
    "        pdf_path=pdf_path,\n",
    "        chunk_size=chunk_size,\n",
    "        overlap=overlap,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"Test Results:\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"✓ PDF Name: {result['pdf_name']}\")\n",
    "    print(f\"✓ Paragraphs Extracted: {result['num_paragraphs']}\")\n",
    "    print(f\"✓ Chunks Created: {result['num_chunks']}\")\n",
    "    print(f\"✓ Vectors Uploaded to VectorDB: {result['total_uploaded']}\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"✓ Knowledge extraction and storage completed successfully!\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"✗ File not found: {str(e)}\")\n",
    "    print(\"Make sure book_1.pdf exists in the test_data directory.\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error during extraction: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85a0309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Test the Extractor class directly (from knowledge_extractor.py)\n",
    "print(\"Testing Extractor class directly:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "from src.knowledge.knowledge_extractor import Extractor\n",
    "\n",
    "try:\n",
    "    extractor = Extractor()\n",
    "    print(\"Extractor initialized successfully!\")\n",
    "    \n",
    "    # Test extraction\n",
    "    pdf_path = \"test_data/book_1.pdf\"\n",
    "    print(f\"\\nExtracting paragraphs from {pdf_path}...\")\n",
    "    paragraphs = extractor.extract(pdf_path)\n",
    "    \n",
    "    print(f\"✓ Extracted {len(paragraphs)} paragraphs\")\n",
    "    \n",
    "    # Show first few paragraphs as sample\n",
    "    if paragraphs:\n",
    "        print(f\"\\nSample paragraphs (first 3):\")\n",
    "        print(\"-\" * 70)\n",
    "        for i, para in enumerate(paragraphs[:3], 1):\n",
    "            print(f\"\\nParagraph {i} (first 200 chars):\")\n",
    "            print(para[:200] + \"...\" if len(para) > 200 else para)\n",
    "        \n",
    "        # Test processing\n",
    "        print(f\"\\n\\nProcessing paragraphs...\")\n",
    "        processed_paragraphs = extractor.process_paragraphs(paragraphs[:3])  # Process first 3 as sample\n",
    "        print(f\"✓ Processed {len(processed_paragraphs)} paragraphs\")\n",
    "        print(\"\\nSample processed paragraph:\")\n",
    "        print(\"-\" * 70)\n",
    "        print(processed_paragraphs[0][:200] + \"...\" if len(processed_paragraphs[0]) > 200 else processed_paragraphs[0])\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"✓ Extractor test completed successfully!\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"✗ File not found: {str(e)}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b379f51",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
