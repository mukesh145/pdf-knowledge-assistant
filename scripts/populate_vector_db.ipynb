{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09c6628",
   "metadata": {},
   "source": [
    "# Populate Pinecone Database with PDF Content\n",
    "\n",
    "This notebook extracts paragraphs from PDF files, processes them, converts them to embeddings, and uploads them to Pinecone DB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70bac451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/miniconda3/envs/mlops/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "import pinecone\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import uuid\n",
    "\n",
    "# Add src/backend to path\n",
    "project_root = Path().resolve()\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from src.backend.query_processing import QueryProcessor\n",
    "from src.backend.context_retriever import ContextRetriever\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44b1850",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up Pinecone connection and configuration parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef857869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index test already exists\n",
      "Connected to index: test\n"
     ]
    }
   ],
   "source": [
    "# Pinecone configuration\n",
    "# Set your Pinecone API key as an environment variable or replace with your key\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\", \"your-pinecone-api-key-here\")\n",
    "PINECONE_INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\", \"pdf-knowledge-base\")\n",
    "PINECONE_ENVIRONMENT = os.getenv(\"PINECONE_ENVIRONMENT\", \"us-east-1\")  # or your preferred region\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Check if index exists, create if it doesn't\n",
    "if PINECONE_INDEX_NAME not in pc.list_indexes().names():\n",
    "    # Create index with dimension 1024 (BAAI/bge-m3 model dimension)\n",
    "    pc.create_index(\n",
    "        name=PINECONE_INDEX_NAME,\n",
    "        dimension=1024,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=PINECONE_ENVIRONMENT\n",
    "        )\n",
    "    )\n",
    "    print(f\"Created new index: {PINECONE_INDEX_NAME}\")\n",
    "else:\n",
    "    print(f\"Index {PINECONE_INDEX_NAME} already exists\")\n",
    "\n",
    "# Connect to the index\n",
    "index = pc.Index(PINECONE_INDEX_NAME)\n",
    "print(f\"Connected to index: {PINECONE_INDEX_NAME}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cabe346",
   "metadata": {},
   "source": [
    "## PDF Processing Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d6539d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_paragraphs_from_pdf(pdf_path: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract paragraphs from a PDF file using unstructured.\n",
    "    Only extracts text content, no other elements.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "        \n",
    "    Returns:\n",
    "        List of paragraph strings extracted from the PDF\n",
    "    \"\"\"\n",
    "    # Partition PDF and extract only text elements\n",
    "    elements = partition_pdf(\n",
    "        filename=pdf_path,\n",
    "        strategy=\"hi_res\",  # High resolution for better text extraction\n",
    "        infer_table_structure=False,  # We only want text\n",
    "        extract_images_in_pdf=False,  # We only want text\n",
    "    )\n",
    "    \n",
    "    # Extract text from elements and filter out empty strings\n",
    "    paragraphs = []\n",
    "    \n",
    "    for element in elements:\n",
    "        # Get text content from element\n",
    "        if hasattr(element, 'text') and element.text:\n",
    "            text = element.text.strip()\n",
    "            if text:\n",
    "                # If element type is a paragraph or similar, add it\n",
    "                if hasattr(element, 'category') and element.category == 'NarrativeText':\n",
    "                    paragraphs.append(text)\n",
    "                elif text:  # Fallback: add any non-empty text\n",
    "                    # Check if it's a substantial paragraph (more than just a few words)\n",
    "                    if len(text.split()) > 5:  # At least 5 words\n",
    "                        paragraphs.append(text)\n",
    "    \n",
    "    # Filter out very short paragraphs (likely headers or noise)\n",
    "    paragraphs = [p for p in paragraphs if len(p.split()) >= 10]  # At least 10 words\n",
    "    \n",
    "    return paragraphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9a9b878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text_with_overlap(text: str, chunk_size: int = 300, overlap: int = 50) -> List[str]:\n",
    "    \"\"\"\n",
    "    Split text into chunks of specified word size with overlap.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text to chunk\n",
    "        chunk_size: Number of words per chunk (default: 300)\n",
    "        overlap: Number of overlapping words between consecutive chunks (default: 50)\n",
    "        \n",
    "    Returns:\n",
    "        List of text chunks\n",
    "    \"\"\"\n",
    "    # Split text into words\n",
    "    words = text.split()\n",
    "    \n",
    "    if len(words) <= chunk_size:\n",
    "        # If text is smaller than chunk size, return as single chunk\n",
    "        return [text]\n",
    "    \n",
    "    chunks = []\n",
    "    start_idx = 0\n",
    "    \n",
    "    while start_idx < len(words):\n",
    "        # Get chunk of words\n",
    "        end_idx = min(start_idx + chunk_size, len(words))\n",
    "        chunk_words = words[start_idx:end_idx]\n",
    "        chunk_text = ' '.join(chunk_words)\n",
    "        chunks.append(chunk_text)\n",
    "        \n",
    "        # Move start index forward by (chunk_size - overlap) to create overlap\n",
    "        start_idx += (chunk_size - overlap)\n",
    "        \n",
    "        # If we're at the end, break\n",
    "        if end_idx >= len(words):\n",
    "            break\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "def chunk_paragraphs(paragraphs: List[str], chunk_size: int = 300, overlap: int = 50) -> List[str]:\n",
    "    \"\"\"\n",
    "    Combine paragraphs and chunk them into segments of specified word size with overlap.\n",
    "    \n",
    "    Args:\n",
    "        paragraphs: List of paragraph strings\n",
    "        chunk_size: Number of words per chunk (default: 300)\n",
    "        overlap: Number of overlapping words between consecutive chunks (default: 50)\n",
    "        \n",
    "    Returns:\n",
    "        List of chunked text segments\n",
    "    \"\"\"\n",
    "    # Combine all paragraphs into one continuous text\n",
    "    combined_text = ' '.join(paragraphs)\n",
    "    \n",
    "    # Chunk the combined text\n",
    "    chunks = chunk_text_with_overlap(combined_text, chunk_size, overlap)\n",
    "    \n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53288c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_paragraphs(paragraphs: List[str], query_processor: QueryProcessor) -> List[str]:\n",
    "    \"\"\"\n",
    "    Process paragraphs using the same algorithm as query processing.\n",
    "    Applies lowercase conversion and whitespace normalization.\n",
    "    \n",
    "    Args:\n",
    "        paragraphs: List of raw paragraph strings\n",
    "        query_processor: QueryProcessor instance for processing\n",
    "        \n",
    "    Returns:\n",
    "        List of processed paragraph strings\n",
    "    \"\"\"\n",
    "    processed_paragraphs = []\n",
    "    for paragraph in paragraphs:\n",
    "        processed = query_processor.process(paragraph)\n",
    "        processed_paragraphs.append(processed)\n",
    "    \n",
    "    return processed_paragraphs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91af409f",
   "metadata": {},
   "source": [
    "## Main Function to Populate Database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9ed833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_pinecone_from_pdf(pdf_path: str, chunk_size: int = 300, overlap: int = 50, batch_size: int = 100):\n",
    "    \"\"\"\n",
    "    Main function to extract paragraphs from PDF, chunk them into segments,\n",
    "    process them, convert to embeddings, and upload to Pinecone DB.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "        chunk_size: Number of words per chunk (default: 300)\n",
    "        overlap: Number of overlapping words between consecutive chunks (default: 50)\n",
    "        batch_size: Number of chunks to process and upload in each batch (default: 100)\n",
    "    \"\"\"\n",
    "    # Resolve PDF path relative to project root\n",
    "    if not Path(pdf_path).is_absolute():\n",
    "        # If relative path, resolve relative to project root\n",
    "        project_root = Path().resolve()\n",
    "        pdf_path = project_root / pdf_path\n",
    "    else:\n",
    "        pdf_path = Path(pdf_path)\n",
    "    \n",
    "    pdf_path = pdf_path.resolve()\n",
    "    if not pdf_path.exists():\n",
    "        raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
    "    \n",
    "    # Get PDF name for metadata\n",
    "    pdf_name = pdf_path.stem\n",
    "    \n",
    "    print(f\"Processing PDF: {pdf_name}\")\n",
    "    print(f\"PDF path: {pdf_path}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Step 1: Extract paragraphs from PDF\n",
    "    print(\"Step 1: Extracting paragraphs from PDF...\")\n",
    "    paragraphs = extract_paragraphs_from_pdf(str(pdf_path))\n",
    "    print(f\"Extracted {len(paragraphs)} paragraphs\")\n",
    "    \n",
    "    if len(paragraphs) == 0:\n",
    "        print(\"Warning: No paragraphs extracted from PDF. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Step 2: Chunk paragraphs into segments of specified size with overlap\n",
    "    print(f\"\\nStep 2: Chunking paragraphs into {chunk_size}-word segments with {overlap}-word overlap...\")\n",
    "    chunked_segments = chunk_paragraphs(paragraphs, chunk_size=chunk_size, overlap=overlap)\n",
    "    print(f\"Created {len(chunked_segments)} chunks\")\n",
    "    \n",
    "    # Step 3: Process chunks using QueryProcessor\n",
    "    print(\"\\nStep 3: Processing chunks...\")\n",
    "    query_processor = QueryProcessor()\n",
    "    processed_chunks = process_paragraphs(chunked_segments, query_processor)\n",
    "    print(f\"Processed {len(processed_chunks)} chunks\")\n",
    "    \n",
    "    # Step 4: Convert to embeddings using ContextRetriever\n",
    "    print(\"\\nStep 4: Converting chunks to embeddings...\")\n",
    "    context_retriever = ContextRetriever()\n",
    "    \n",
    "    # Process in batches to avoid memory issues\n",
    "    total_uploaded = 0\n",
    "    num_batches = (len(processed_chunks) + batch_size - 1) // batch_size\n",
    "    \n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min((batch_idx + 1) * batch_size, len(processed_chunks))\n",
    "        batch_chunks = processed_chunks[start_idx:end_idx]\n",
    "        batch_original = chunked_segments[start_idx:end_idx]  # Keep original for storage\n",
    "        \n",
    "        print(f\"Processing batch {batch_idx + 1}/{num_batches} ({len(batch_chunks)} chunks)...\")\n",
    "        \n",
    "        # Convert batch to embeddings\n",
    "        embeddings = context_retriever.convert_batch_to_embeddings(batch_chunks)\n",
    "        \n",
    "        # Ensure embeddings is a 2D numpy array\n",
    "        if embeddings.ndim == 1:\n",
    "            embeddings = embeddings.reshape(1, -1)\n",
    "        \n",
    "        # Step 5: Prepare vectors for Pinecone upload\n",
    "        vectors_to_upload = []\n",
    "        for i in range(len(batch_chunks)):\n",
    "            # Get embedding for this chunk (handle both 1D and 2D arrays)\n",
    "            if embeddings.ndim == 2:\n",
    "                embedding = embeddings[i]\n",
    "            else:\n",
    "                embedding = embeddings\n",
    "            \n",
    "            # Generate unique ID for each vector\n",
    "            vector_id = str(uuid.uuid4())\n",
    "            \n",
    "            # Prepare metadata\n",
    "            metadata = {\n",
    "                \"pdf_name\": pdf_name,\n",
    "                \"chunk_index\": start_idx + i,\n",
    "                \"text\": batch_original[i],  # Store original text for retrieval\n",
    "                \"processed_text\": batch_chunks[i]  # Store processed text for reference\n",
    "            }\n",
    "            \n",
    "            vectors_to_upload.append({\n",
    "                \"id\": vector_id,\n",
    "                \"values\": embedding.tolist(),  # Convert numpy array to list\n",
    "                \"metadata\": metadata\n",
    "            })\n",
    "        \n",
    "        # Upload batch to Pinecone\n",
    "        print(f\"Uploading batch {batch_idx + 1} to Pinecone...\")\n",
    "        index.upsert(vectors=vectors_to_upload)\n",
    "        total_uploaded += len(vectors_to_upload)\n",
    "        print(f\"Uploaded {len(vectors_to_upload)} vectors (Total: {total_uploaded})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"Successfully uploaded {total_uploaded} vectors to Pinecone!\")\n",
    "    print(f\"PDF: {pdf_name}\")\n",
    "    print(f\"Chunk size: {chunk_size} words, Overlap: {overlap} words\")\n",
    "    print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897425aa",
   "metadata": {},
   "source": [
    "## Usage Example\n",
    "\n",
    "Run the function with the path to your PDF file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bf493c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: takamuku2009\n",
      "PDF path: /Users/user/Desktop/pdf-knowledge-assistant/test_data/takamuku2009.pdf\n",
      "--------------------------------------------------\n",
      "Step 1: Extracting paragraphs from PDF...\n",
      "Warning: No languages specified, defaulting to English.\n",
      "Extracted 136 paragraphs\n",
      "\n",
      "Step 2: Chunking paragraphs into 300-word segments with 50-word overlap...\n",
      "Created 26 chunks\n",
      "\n",
      "Step 3: Processing chunks...\n",
      "Processed 26 chunks\n",
      "\n",
      "Step 4: Converting chunks to embeddings...\n",
      "Processing batch 1/1 (26 chunks)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading batch 1 to Pinecone...\n",
      "Uploaded 26 vectors (Total: 26)\n",
      "\n",
      "==================================================\n",
      "Successfully uploaded 26 vectors to Pinecone!\n",
      "PDF: takamuku2009\n",
      "Chunk size: 300 words, Overlap: 50 words\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "# Replace with the path to your PDF file\n",
    "# Path is relative to the project root\n",
    "pdf_file_path = \"test_data/takamuku2009.pdf\"\n",
    "\n",
    "# Populate Pinecone database\n",
    "# Chunks will be 300 words with 50-word overlap\n",
    "populate_pinecone_from_pdf(pdf_file_path, chunk_size=300, overlap=50, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061af29d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54228502",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
